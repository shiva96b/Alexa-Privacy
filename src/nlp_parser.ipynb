{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-9fAvDop5gO",
        "outputId": "0c5cca00-2dce-4c93-ffd1-b927a4ca52a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('tagsets')\n",
        "from nltk import word_tokenize\n",
        "from nltk.data import load\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Unzipping help/tagsets.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnQlcYlmp-lK",
        "outputId": "11735255-1c16-4686-84a3-9c5d0e4efde4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "# POS Tagging\n",
        "\n",
        "tagdict = load('help/tagsets/upenn_tagset.pickle')\n",
        "pos_tags_list = list(tagdict.keys())\n",
        "pos_dict = dict.fromkeys(pos_tags_list, 0)\n",
        "tags = []\n",
        "flagged = ['name', 'address', 'email', 'phone number']\n",
        "conversation = ['I can address the problem.', 'What is the address?', 'What is your phone number?', 'Our phone number is 9199199199.']\n",
        "\n",
        "for sen in conversation:\n",
        " tags.append(nltk.pos_tag(word_tokenize(sen)))\n",
        "\n",
        "tags"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('I', 'PRP'),\n",
              "  ('can', 'MD'),\n",
              "  ('address', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('problem', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('What', 'WP'), ('is', 'VBZ'), ('the', 'DT'), ('address', 'NN'), ('?', '.')],\n",
              " [('What', 'WP'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('your', 'PRP$'),\n",
              "  ('phone', 'NN'),\n",
              "  ('number', 'NN'),\n",
              "  ('?', '.')],\n",
              " [('Our', 'PRP$'),\n",
              "  ('phone', 'NN'),\n",
              "  ('number', 'NN'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('9199199199', 'CD'),\n",
              "  ('.', '.')]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNMDUkRdqPnD",
        "outputId": "5f8c9843-50be-4b83-d23b-736e532fdbdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "# Parse Tree\n",
        "from nltk import Tree\n",
        "\n",
        "pattern = \"\"\"NP: {<DT>?<JJ>*<NN>}\n",
        "VBD: {<VBD>}\n",
        "IN: {<IN>}\"\"\"\n",
        "\n",
        "NPChunker = nltk.RegexpParser(pattern) \n",
        "\n",
        "for sen in tags:\n",
        "  result = NPChunker.parse(sen)\n",
        "  Tree.fromstring(str(result)).pretty_print()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 S                           \n",
            "   ______________|______________              \n",
            "  |     |        |              NP           \n",
            "  |     |        |         _____|______       \n",
            "I/PRP can/MD address/VB the/DT     problem/NN\n",
            "\n",
            "                S                       \n",
            "    ____________|__________              \n",
            "   |      |     |          NP           \n",
            "   |      |     |     _____|______       \n",
            "What/WP is/VBZ ?/. the/DT     address/NN\n",
            "\n",
            "                S                               \n",
            "    ____________|__________________________      \n",
            "   |      |     |          NP              NP   \n",
            "   |      |     |     _____|_____          |     \n",
            "What/WP is/VBZ ?/. the/DT     phone/NN number/NN\n",
            "\n",
            "                       S                          \n",
            "    ___________________|_____________________      \n",
            "   |       |           |           NP        NP   \n",
            "   |       |           |           |         |     \n",
            "Our/PRP$ is/VBZ 919-xxx-xxxx/JJ phone/NN number/NN\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iCqycFaZQwz"
      },
      "source": [
        "# Stanza\n",
        "\n",
        "The Stanford NLP Group's official Python NLP library. It contains support for running various accurate natural language processing tools on 60+ languages and for accessing the Java Stanford CoreNLP software from Python. \n",
        "\n",
        "For detailed information please visit https://stanfordnlp.github.io/stanza/."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf69BCf2XS_M",
        "outputId": "ca461b6a-e965-40f4-dbb5-3703a25fd710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "!pip install stanza"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stanza\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/8b/3a9e7a8d8cb14ad6afffc3983b7a7322a3a24d94ebc978a70746fcffc085/stanza-1.1.1-py3-none-any.whl (227kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 18.1MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |████▎                           | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 61kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 71kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 92kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 102kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 112kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 122kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 133kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 143kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 153kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 163kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 174kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 184kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 194kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 204kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 215kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 225kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from stanza) (3.12.4)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from stanza) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stanza) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from stanza) (4.41.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (50.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->stanza) (0.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2.10)\n",
            "Installing collected packages: stanza\n",
            "Successfully installed stanza-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwB7kXC-VnIM",
        "outputId": "b0cbbf9b-327f-48be-d378-5d11492181ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "import stanza\n",
        "stanza.download('en')       # This downloads the English models for the neural pipeline\n",
        "nlp = stanza.Pipeline('en') # This sets up a default neural pipeline in English"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.1.0.json: 122kB [00:00, 11.4MB/s]                    \n",
            "2020-10-05 10:49:03 INFO: Downloading default packages for language: en (English)...\n",
            "2020-10-05 10:49:05 INFO: File exists: /root/stanza_resources/en/default.zip.\n",
            "2020-10-05 10:49:11 INFO: Finished downloading models and saved to /root/stanza_resources.\n",
            "2020-10-05 10:49:11 INFO: Loading these models for language: en (English):\n",
            "=========================\n",
            "| Processor | Package   |\n",
            "-------------------------\n",
            "| tokenize  | ewt       |\n",
            "| pos       | ewt       |\n",
            "| lemma     | ewt       |\n",
            "| depparse  | ewt       |\n",
            "| sentiment | sstplus   |\n",
            "| ner       | ontonotes |\n",
            "=========================\n",
            "\n",
            "2020-10-05 10:49:11 INFO: Use device: cpu\n",
            "2020-10-05 10:49:11 INFO: Loading: tokenize\n",
            "2020-10-05 10:49:11 INFO: Loading: pos\n",
            "2020-10-05 10:49:12 INFO: Loading: lemma\n",
            "2020-10-05 10:49:12 INFO: Loading: depparse\n",
            "2020-10-05 10:49:13 INFO: Loading: sentiment\n",
            "2020-10-05 10:49:14 INFO: Loading: ner\n",
            "2020-10-05 10:49:15 INFO: Done loading processors!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SQDc0ZlYOpW",
        "outputId": "f934f150-fbba-4f8a-a06b-71444eaf971a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "doc = nlp(\"I can address the problem. What is your address? My address is xxx\")\n",
        "doc.sentences[0].print_dependencies()\n",
        "doc.sentences[1].print_dependencies()\n",
        "doc.sentences[2].print_dependencies()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('I', 3, 'nsubj')\n",
            "('can', 3, 'aux')\n",
            "('address', 0, 'root')\n",
            "('the', 5, 'det')\n",
            "('problem', 3, 'obj')\n",
            "('.', 3, 'punct')\n",
            "('What', 0, 'root')\n",
            "('is', 1, 'cop')\n",
            "('your', 4, 'nmod:poss')\n",
            "('address', 1, 'nsubj')\n",
            "('?', 1, 'punct')\n",
            "('My', 2, 'nmod:poss')\n",
            "('address', 4, 'nsubj')\n",
            "('is', 4, 'cop')\n",
            "('xxx', 0, 'root')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3SKYiBzdzGS",
        "outputId": "80f3fd06-2351-4515-f37e-9ad2c31e732e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "doc = nlp(' '.join(conversation))\n",
        "\n",
        "for parsed_sentence in doc.sentences:\n",
        "  flag = 0\n",
        "  pos_tags = parsed_sentence.to_dict()\n",
        "  print(pos_tags)\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'id': 1, 'text': 'I', 'lemma': 'I', 'upos': 'PRON', 'xpos': 'PRP', 'feats': 'Case=Nom|Number=Sing|Person=1|PronType=Prs', 'head': 3, 'deprel': 'nsubj', 'misc': 'start_char=0|end_char=1', 'ner': 'O'}, {'id': 2, 'text': 'can', 'lemma': 'can', 'upos': 'AUX', 'xpos': 'MD', 'feats': 'VerbForm=Fin', 'head': 3, 'deprel': 'aux', 'misc': 'start_char=2|end_char=5', 'ner': 'O'}, {'id': 3, 'text': 'address', 'lemma': 'address', 'upos': 'VERB', 'xpos': 'VB', 'feats': 'VerbForm=Inf', 'head': 0, 'deprel': 'root', 'misc': 'start_char=6|end_char=13', 'ner': 'O'}, {'id': 4, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'feats': 'Definite=Def|PronType=Art', 'head': 5, 'deprel': 'det', 'misc': 'start_char=14|end_char=17', 'ner': 'O'}, {'id': 5, 'text': 'problem', 'lemma': 'problem', 'upos': 'NOUN', 'xpos': 'NN', 'feats': 'Number=Sing', 'head': 3, 'deprel': 'obj', 'misc': 'start_char=18|end_char=25', 'ner': 'O'}, {'id': 6, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 3, 'deprel': 'punct', 'misc': 'start_char=25|end_char=26', 'ner': 'O'}]\n",
            "[{'id': 1, 'text': 'What', 'lemma': 'what', 'upos': 'PRON', 'xpos': 'WP', 'feats': 'PronType=Int', 'head': 0, 'deprel': 'root', 'misc': 'start_char=27|end_char=31', 'ner': 'O'}, {'id': 2, 'text': 'is', 'lemma': 'be', 'upos': 'AUX', 'xpos': 'VBZ', 'feats': 'Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin', 'head': 1, 'deprel': 'cop', 'misc': 'start_char=32|end_char=34', 'ner': 'O'}, {'id': 3, 'text': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'feats': 'Definite=Def|PronType=Art', 'head': 4, 'deprel': 'det', 'misc': 'start_char=35|end_char=38', 'ner': 'O'}, {'id': 4, 'text': 'address', 'lemma': 'address', 'upos': 'NOUN', 'xpos': 'NN', 'feats': 'Number=Sing', 'head': 1, 'deprel': 'nsubj', 'misc': 'start_char=39|end_char=46', 'ner': 'O'}, {'id': 5, 'text': '?', 'lemma': '?', 'upos': 'PUNCT', 'xpos': '.', 'head': 1, 'deprel': 'punct', 'misc': 'start_char=46|end_char=47', 'ner': 'O'}]\n",
            "[{'id': 1, 'text': 'What', 'lemma': 'what', 'upos': 'PRON', 'xpos': 'WP', 'feats': 'PronType=Int', 'head': 0, 'deprel': 'root', 'misc': 'start_char=48|end_char=52', 'ner': 'O'}, {'id': 2, 'text': 'is', 'lemma': 'be', 'upos': 'AUX', 'xpos': 'VBZ', 'feats': 'Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin', 'head': 1, 'deprel': 'cop', 'misc': 'start_char=53|end_char=55', 'ner': 'O'}, {'id': 3, 'text': 'your', 'lemma': 'you', 'upos': 'PRON', 'xpos': 'PRP$', 'feats': 'Person=2|Poss=Yes|PronType=Prs', 'head': 5, 'deprel': 'nmod:poss', 'misc': 'start_char=56|end_char=60', 'ner': 'O'}, {'id': 4, 'text': 'phone', 'lemma': 'phone', 'upos': 'NOUN', 'xpos': 'NN', 'feats': 'Number=Sing', 'head': 5, 'deprel': 'compound', 'misc': 'start_char=61|end_char=66', 'ner': 'O'}, {'id': 5, 'text': 'number', 'lemma': 'number', 'upos': 'NOUN', 'xpos': 'NN', 'feats': 'Number=Sing', 'head': 1, 'deprel': 'nsubj', 'misc': 'start_char=67|end_char=73', 'ner': 'O'}, {'id': 6, 'text': '?', 'lemma': '?', 'upos': 'PUNCT', 'xpos': '.', 'head': 1, 'deprel': 'punct', 'misc': 'start_char=73|end_char=74', 'ner': 'O'}]\n",
            "[{'id': 1, 'text': 'Our', 'lemma': 'we', 'upos': 'PRON', 'xpos': 'PRP$', 'feats': 'Number=Plur|Person=1|Poss=Yes|PronType=Prs', 'head': 3, 'deprel': 'nmod:poss', 'misc': 'start_char=75|end_char=78', 'ner': 'O'}, {'id': 2, 'text': 'phone', 'lemma': 'phone', 'upos': 'NOUN', 'xpos': 'NN', 'feats': 'Number=Sing', 'head': 3, 'deprel': 'compound', 'misc': 'start_char=79|end_char=84', 'ner': 'O'}, {'id': 3, 'text': 'number', 'lemma': 'number', 'upos': 'NOUN', 'xpos': 'NN', 'feats': 'Number=Sing', 'head': 5, 'deprel': 'nsubj', 'misc': 'start_char=85|end_char=91', 'ner': 'O'}, {'id': 4, 'text': 'is', 'lemma': 'be', 'upos': 'AUX', 'xpos': 'VBZ', 'feats': 'Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin', 'head': 5, 'deprel': 'cop', 'misc': 'start_char=92|end_char=94', 'ner': 'O'}, {'id': 5, 'text': '9199199199', 'lemma': '9199199199', 'upos': 'NUM', 'xpos': 'CD', 'feats': 'NumType=Card', 'head': 0, 'deprel': 'root', 'misc': 'start_char=95|end_char=105', 'ner': 'S-CARDINAL'}, {'id': 6, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'head': 5, 'deprel': 'punct', 'misc': 'start_char=105|end_char=106', 'ner': 'O'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GofrzxNb3To"
      },
      "source": [
        "# Verb differentiation for 'address' \n",
        "# Implement the Skills Conflicting with the Developer Specifications methond [Section 4.2 in the paper[1]]\n",
        "\n",
        "sentence_flagged = []\n",
        "\n",
        "for parsed_sentence in doc.sentences:\n",
        "  flag_noun, flag_object = 0,0\n",
        "  pos_tags = parsed_sentence.to_dict()\n",
        "  \n",
        "  for word in pos_tags:\n",
        "    \n",
        "    # Identify if the flagged words are addressed as nouns\n",
        "    if (word['text'] == 'address' or word['text'] == 'phone' or  word['text'] == 'number') and word['upos'] == 'NOUN':\n",
        "      flag_noun = 1\n",
        "\n",
        "    # Identify if the subject addressed is the user in the conversation\n",
        "    if (word['text'] == 'you' or word['text'] == 'your') and word['deprel'] == 'nmod:poss':\n",
        "      flag_object = 1\n",
        "\n",
        "  sentence_flagged.append(flag_noun and flag_object) \n",
        "    "
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwLSaB1TiCdA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OMUZtaOg-GR"
      },
      "source": [
        "# References:\n",
        "\n",
        "* https://www.usenix.org/conference/usenixsecurity20/presentation/guo\n",
        "* https://corenlp.run/\n",
        "* https://github.com/stanfordnlp/stanza/"
      ]
    }
  ]
}